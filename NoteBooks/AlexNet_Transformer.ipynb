{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-19T14:29:34.616077Z","iopub.status.busy":"2023-12-19T14:29:34.615274Z","iopub.status.idle":"2023-12-19T14:29:46.805558Z","shell.execute_reply":"2023-12-19T14:29:46.804119Z","shell.execute_reply.started":"2023-12-19T14:29:34.616036Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import keras.utils as image\n","from sklearn.preprocessing import OneHotEncoder\n","from keras.src.utils import to_categorical,normalize\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n","from keras.callbacks import EarlyStopping\n","from keras.optimizers import Adam\n","import keras.layers as layers\n","from keras.models import Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:29:46.808227Z","iopub.status.busy":"2023-12-19T14:29:46.807612Z","iopub.status.idle":"2023-12-19T14:29:57.411495Z","shell.execute_reply":"2023-12-19T14:29:57.410515Z","shell.execute_reply.started":"2023-12-19T14:29:46.808194Z"},"trusted":true},"outputs":[],"source":["for dirname, _, filenames in os.walk(\"/kaggle/input/dataset-nn23\"):\n","    Image_Count = 0\n","#     print(dirname)\n","\n","    for file in filenames:\n","        Image_Count += 1\n","\n","    if Image_Count > 0:\n","        print('Total Files in directory {} is {}'.format(dirname, Image_Count))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:29:57.412904Z","iopub.status.busy":"2023-12-19T14:29:57.412611Z","iopub.status.idle":"2023-12-19T14:29:57.417267Z","shell.execute_reply":"2023-12-19T14:29:57.416259Z","shell.execute_reply.started":"2023-12-19T14:29:57.412879Z"},"trusted":true},"outputs":[],"source":["train_path = '/kaggle/input/dataset-nn23/dataset/train/'\n","test_path = '/kaggle/input/dataset-nn23/dataset/test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:29:57.419631Z","iopub.status.busy":"2023-12-19T14:29:57.419354Z","iopub.status.idle":"2023-12-19T14:30:54.337197Z","shell.execute_reply":"2023-12-19T14:30:54.336292Z","shell.execute_reply.started":"2023-12-19T14:29:57.419607Z"},"trusted":true},"outputs":[],"source":["IMG_SIZE = 250\n","classes = ['1', '2', '3', '4', '5']\n","Input_Shape = (IMG_SIZE, IMG_SIZE, 3)\n","images = []\n","labels = []\n","for c in classes:\n","    for img in os.listdir(train_path + c):\n","        img = cv2.imread(train_path + c + '/' + img)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","        images.append(img)\n","        labels.append(int(c))\n","        \n","images = np.array(images, dtype='float32')/255.0        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:30:54.338681Z","iopub.status.busy":"2023-12-19T14:30:54.338379Z","iopub.status.idle":"2023-12-19T14:30:54.351296Z","shell.execute_reply":"2023-12-19T14:30:54.350494Z","shell.execute_reply.started":"2023-12-19T14:30:54.338655Z"},"trusted":true},"outputs":[],"source":["onehotencoder = OneHotEncoder()\n","label = np.array(labels).reshape(-1,1)\n","labels = onehotencoder.fit_transform(label).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:30:54.353437Z","iopub.status.busy":"2023-12-19T14:30:54.352998Z","iopub.status.idle":"2023-12-19T14:30:56.369984Z","shell.execute_reply":"2023-12-19T14:30:56.368698Z","shell.execute_reply.started":"2023-12-19T14:30:54.353401Z"},"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:30:56.372278Z","iopub.status.busy":"2023-12-19T14:30:56.371762Z","iopub.status.idle":"2023-12-19T14:30:56.379493Z","shell.execute_reply":"2023-12-19T14:30:56.378151Z","shell.execute_reply.started":"2023-12-19T14:30:56.372214Z"},"trusted":true},"outputs":[],"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(type(y_val))\n","print(type(X_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:30:56.381017Z","iopub.status.busy":"2023-12-19T14:30:56.380732Z","iopub.status.idle":"2023-12-19T14:30:58.925628Z","shell.execute_reply":"2023-12-19T14:30:58.924663Z","shell.execute_reply.started":"2023-12-19T14:30:56.380993Z"},"trusted":true},"outputs":[],"source":["X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:30:58.927823Z","iopub.status.busy":"2023-12-19T14:30:58.927173Z","iopub.status.idle":"2023-12-19T14:31:01.199589Z","shell.execute_reply":"2023-12-19T14:31:01.198683Z","shell.execute_reply.started":"2023-12-19T14:30:58.927785Z"},"trusted":true},"outputs":[],"source":["training_datagen = ImageDataGenerator(\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    zoom_range=0.2,\n","    fill_mode=\"nearest\",\n",")\n","\n","training_datagen.fit(X_train)\n","training_datagen.fit(X_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:31:01.205072Z","iopub.status.busy":"2023-12-19T14:31:01.204331Z","iopub.status.idle":"2023-12-19T14:31:01.209497Z","shell.execute_reply":"2023-12-19T14:31:01.208625Z","shell.execute_reply.started":"2023-12-19T14:31:01.205037Z"},"trusted":true},"outputs":[],"source":["print(X_val.shape)\n","print(y_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:31:01.248220Z","iopub.status.busy":"2023-12-19T14:31:01.247882Z","iopub.status.idle":"2023-12-19T14:31:04.400268Z","shell.execute_reply":"2023-12-19T14:31:04.399402Z","shell.execute_reply.started":"2023-12-19T14:31:01.248193Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","# Create a Positional Encoding layer\n","class PositionalEncoding(layers.Layer):\n","    def __init__(self, max_len, embedding_dim):\n","        super(PositionalEncoding, self).__init__()\n","        self.encoding = self.positional_encoding(max_len, embedding_dim)\n","\n","    def positional_encoding(self, max_len, embedding_dim):\n","        position = tf.range(max_len, dtype=tf.float32)[:, tf.newaxis]\n","        div_term = tf.exp(tf.range(0, embedding_dim, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / embedding_dim))\n","        pos_enc = position * div_term\n","        pos_enc = tf.stack([tf.sin(pos_enc), tf.cos(pos_enc)], axis=-1)\n","        pos_enc = tf.reshape(pos_enc, [max_len, 1, embedding_dim])\n","        return pos_enc\n","\n","    def call(self, inputs):\n","        return inputs + self.encoding\n","\n","# Create a Transformer Encoder layer\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embedding_dim, num_heads=8, ff_dim=1024, dropout=0.1, name=\"transformer_encoder\"):\n","        super(TransformerEncoder, self).__init__(name=name)\n","\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim // num_heads)\n","        self.ffn = models.Sequential([\n","            layers.Dense(ff_dim, activation=\"relu\"),\n","            layers.Dropout(dropout),\n","            layers.Dense(embedding_dim),\n","        ])\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(dropout)\n","        self.dropout2 = layers.Dropout(dropout)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# Create a modified AlexNet with Transformer Encoder and Positional Encoding\n","def create_transformer_alexnet(input_shape, num_classes, embedding_dim=256, num_heads=8):\n","    # Define AlexNet architecture up to the transformer encoder layer\n","    base_model = models.Sequential([\n","        layers.Conv2D(96, 11, strides=(4, 4), padding='valid', input_shape=input_shape, activation='relu'),\n","        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(256, 5, strides=(1, 1), padding='valid', activation='relu'),\n","        layers.Conv2D(256, 5, strides=(1, 1), padding='valid', activation='relu'),\n","        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(384, 3, strides=(1, 1), padding='valid', activation='relu'),\n","        layers.Conv2D(384, 3, strides=(1, 1), padding='valid', activation='relu'),\n","        layers.Conv2D(256, 3, strides=(1, 1), padding='valid', activation='relu'),\n","        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n","        layers.BatchNormalization(),\n","    ])\n","\n","    # Extract features from AlexNet\n","    features = base_model.output\n","    \n","    # Add positional encoding layer\n","    max_len = tf.reduce_prod(features.shape[1:-1])\n","    pos_encoding = PositionalEncoding(max_len, embedding_dim)(features)\n","\n","    # Add transformer encoder layer\n","    transformer_encoder = TransformerEncoder(embedding_dim, num_heads)(pos_encoding)\n","\n","    # Flatten the output before applying Global Average Pooling\n","    flattened_transformer = layers.Flatten()(transformer_encoder)\n","    \n","    # Add dense layers for classification\n","    x = layers.Dense(256, activation='relu')(flattened_transformer)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(num_classes, activation='softmax')(x)\n","    \n","    # Create the final model\n","    model = models.Model(inputs=base_model.input, outputs=x)\n","    \n","    return model\n","\n","# Example usage:\n","input_shape = (250, 250, 3)\n","num_classes = 5  # adjust based on your task\n","model = create_transformer_alexnet(input_shape, num_classes)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:31:04.401936Z","iopub.status.busy":"2023-12-19T14:31:04.401545Z","iopub.status.idle":"2023-12-19T14:31:04.424801Z","shell.execute_reply":"2023-12-19T14:31:04.423774Z","shell.execute_reply.started":"2023-12-19T14:31:04.401898Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","model.compile(optimizer='adam', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","callbacks = [\n","    EarlyStopping(patience=10, restore_best_weights=True)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T14:31:04.431696Z","iopub.status.busy":"2023-12-19T14:31:04.431273Z","iopub.status.idle":"2023-12-19T16:02:01.671452Z","shell.execute_reply":"2023-12-19T16:02:01.670461Z","shell.execute_reply.started":"2023-12-19T14:31:04.431652Z"},"trusted":true},"outputs":[],"source":["history=model.fit(training_datagen.flow(X_train, y_train, batch_size=64),\n","         validation_data=training_datagen.flow(X_val, y_val),epochs=100,steps_per_epoch=130, callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T16:02:01.672991Z","iopub.status.busy":"2023-12-19T16:02:01.672702Z","iopub.status.idle":"2023-12-19T16:02:02.276968Z","shell.execute_reply":"2023-12-19T16:02:02.276194Z","shell.execute_reply.started":"2023-12-19T16:02:01.672965Z"},"trusted":true},"outputs":[],"source":["#plot the training and validation accuracy and loss at each epoch\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'y', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","plt.plot(epochs, acc, 'y', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T16:02:02.278387Z","iopub.status.busy":"2023-12-19T16:02:02.278082Z","iopub.status.idle":"2023-12-19T16:02:06.561435Z","shell.execute_reply":"2023-12-19T16:02:06.560516Z","shell.execute_reply.started":"2023-12-19T16:02:02.278360Z"},"trusted":true},"outputs":[],"source":["score = model.evaluate(X_val, y_val, verbose = 0 )\n","print(\"Test Loss: \", score[0])\n","print(\"Test accuracy: \", score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T16:02:06.563447Z","iopub.status.busy":"2023-12-19T16:02:06.562795Z","iopub.status.idle":"2023-12-19T16:02:07.499541Z","shell.execute_reply":"2023-12-19T16:02:07.498531Z","shell.execute_reply.started":"2023-12-19T16:02:06.563410Z"},"trusted":true},"outputs":[],"source":["X_test = []\n","image_coulmn=[]\n","for img in os.listdir(test_path):\n","    image_coulmn.append(int((img.split('.'))[0]))\n","    img = cv2.imread(test_path + img)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    # Preprocess the image if needed (e.g., resizing, normalization)\n","    img = cv2.resize(img,(250, 250))  # Resize to match your target size\n","    X_test.append(img)\n","\n","# Convert the list of images to a NumPy array\n","X_test = np.array(X_test)/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T16:02:07.501338Z","iopub.status.busy":"2023-12-19T16:02:07.500940Z","iopub.status.idle":"2023-12-19T16:02:08.520456Z","shell.execute_reply":"2023-12-19T16:02:08.519485Z","shell.execute_reply.started":"2023-12-19T16:02:07.501301Z"},"trusted":true},"outputs":[],"source":["Output=model.predict(X_test, batch_size=64, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T16:02:08.521997Z","iopub.status.busy":"2023-12-19T16:02:08.521694Z","iopub.status.idle":"2023-12-19T16:02:08.528081Z","shell.execute_reply":"2023-12-19T16:02:08.527195Z","shell.execute_reply.started":"2023-12-19T16:02:08.521971Z"},"trusted":true},"outputs":[],"source":["Prediction_classes=[]\n","for predict in Output:\n","    index=np.argmax(predict)\n","    Prediction_classes.append(index+1)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4137621,"sourceId":7163149,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
